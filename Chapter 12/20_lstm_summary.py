# LSTM summary

print("=" * 50)
print("LSTM SUMMARY")
print("=" * 50)
print()
print("PROBLEM: RNN vanishing gradients")
print()
print("SOLUTION: LSTM with gates and cell state")
print()
print("KEY COMPONENTS:")
print("  - Cell state: memory highway")
print("  - Forget gate: what to remove")
print("  - Input gate: what to add")
print("  - Output gate: what to output")
print()
print("EQUATIONS:")
print("  f = sigmoid(W_f * [h, x])")
print("  i = sigmoid(W_i * [h, x])")
print("  c_tilde = tanh(W_c * [h, x])")
print("  o = sigmoid(W_o * [h, x])")
print("  c_new = f * c + i * c_tilde")
print("  h_new = o * tanh(c_new)")
print()
print("WHY IT WORKS:")
print("  - gradient flows through f gate")
print("  - if f~1, gradient preserved")
print("  - learns long-range dependencies")
print()
print("VARIANTS:")
print("  - GRU: simpler, 2 gates")
print("  - Peephole: gates see cell state")
print("  - Bidirectional: both directions")
print()
print("LSTM = breakthrough for sequence modeling!")
